{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = pd.read_csv('shakespeare-plays/Shakespeare_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataline is like an id -- largely useless data we can discard from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lines['Dataline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the lines in this dataset are actually stage directions.  Since these are not actually spoken by a player, it makes sense that we would want to exclude these points.  One other line is also mysteriously lacking a player, which messes with learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines.query('not ActSceneLine.isnull()')\n",
    "lines = lines.query('not Player.isnull()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Engineering\n",
    "This first section focuses on feature engineering from the lines spoken by players.\n",
    "\n",
    "Stripping out non alphanumerics helps improve accuracy, since commas, apostrophes, and the like are mostly noise that will confuse models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines.assign(\n",
    "    PlayerLine=lines['PlayerLine'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most important stage in text feature engineering.  The CountVectorizer converts each text input into a vector that records the count of each word, in a technique known as 'bag of words'.  The resultant matrix has one column assigned to each word that appears in the inputs.  This matrix can then be applied to classic learning models, such as linear regression and support vector machines.  Deep learning techniques, such as neural networks, can also be trained on the data, but these models are typically much slower, and the output of the CountVectorizer is large.\n",
    "\n",
    "The count vectorizer also comes with a set of stop words that can be used.  Stop words are sets of words such as 'a', 'an', 'and', 'the', etc., that have been identified as having little semantic meaning.  Removing these words, as the CountVectorizer does, can help improve training accuracy since it is a source of noise.  Adding stop words improved training accuracy by about 2%.  Note that these stopwords are intended for modern english, and thus may only be partially applicable to shakespearean english.  A hand-tailored set of stopwords would likely yield additional improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "cv_matrix = cv.fit_transform(lines['PlayerLine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other feature engineering\n",
    "Play names are one-hot encoded for ease of model training.  This is a more machine-readable format for this data than the text representation of the play.\n",
    "\n",
    "Act-scene-line data is converted into labels, since this text format doesn't easily convert to numbers on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "lines[['ActSceneLine']] = lines[['ActSceneLine']].apply(\n",
    "    lambda col: le.fit_transform(col)\n",
    ")\n",
    "\n",
    "play_onehot = pd.get_dummies(lines['Play'], prefix='Play', sparse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engineered data is stacked together horizontally into a single matrix, then separated into a training and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = hstack((lines[['PlayerLinenumber', 'ActSceneLine']], play_onehot, cv_matrix))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_data, lines['Player'], test_size=.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are a nice choice for this dataset, since they train quickly (and we have a *lot* of engineered data) and can get surprisingly good results for such short training times.  Our final accuracy is about 72%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7230710708172193\n"
     ]
    }
   ],
   "source": [
    "t = tree.DecisionTreeClassifier()\n",
    "t.fit(X_train, y_train)\n",
    "print(t.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
